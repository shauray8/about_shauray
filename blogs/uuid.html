<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>UUIDs - Mess Withing a Widely Used Standard</title>
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="Discovering secret seeds in Text-to-Image Diffusion Models">
    <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Shauray Singh blog posts" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="main.css">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1DD05WB973"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-RLJ3MKG26H');
    </script>

</head>


    <body>

    <header class="site-header">

  <div class="wrap">

    <a class="site-title" href="./blog.html">We Must Know, We Will Know</a>
    
</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">

  <header class="post-header">
    <h1>UUIDs - Mess Withing a Widely Used Standard</h1>
    <p class="meta">Jun 18, 2024</p>
  </header>

  <article class="post-content">
  <style>
.post-header h1 {
    font-size: 35px;
}
.post pre,
.post code {
    background-color: #fcfcfc;
    font-size: 13px; /* make code smaller for this post... */
}
</style>

<p>It's time to dive into the wild, wacky, and sometimes downright infuriating world of UUIDs. Yes, those strings of alphanumeric chaos that we love to hate and hate to love We're not here to explain what UUIDs are (Google that if you must), but rather to vent, rant, and explore some wild ideas about how V7 can help in some ways, specially with S3s (S3s requires a seperate rant of it's own)</p>
<h3>A quick overview of what a mess of versions it is !</h3>
<p>I really like this illustration from <a href='https://www.youtube.com/@t3dotgg/'>@t3dotgg</a> and this post <a href='https://planetscale.com/blog/the-problem-with-using-a-uuid-primary-key-in-mysql'>The Problem with Using a UUID Primary Key in MySQL</a> will give you a very good explaination of how messed up this is, which basically translates to, <br> </p>
<ul>
  <li> <b>UUIDv1</b> - Uses the Gregorian calendar &#x1F937;&#x200D;&#x2642;&#xFE0F; segments looks like <b>['time_low'-'time_mid'-'time_low_and_version'-'clock_seq_and_version'-'node'] </b>- now using the Gregorian calendar is not the biggest issues here, rather they had the biggest segment set to <b>'node'</b> which is the unique address of the system generating the UUID. I'm no security expert but this looks bad </li>
  <br>
  <li> <b>UUIDv2</b> - nothing intresting here, they replaced the <b>'low_time'</b> component of the UUID with POSIX user ID </li>
  <br>
  <li><b>UUIDv3 and v5</b> - they started using a <b>128bit</b> hash and both versions use a different hash MD5 and SHA1 repectively, the intresting part here is that V3 and V5 is similar but not V4, and V4 is what is widely used</li>
  <br>
  <li><b>UUIDv4</b> - this is what most of the population uses for there random keys and in my opinion this is the simplest of them all, <b>it just uses a set of random alphanumerics</b>, with an exception that the first position of the 3rd segment is always set to the version number (seen throughout the versions) </li>
  <br>
  <li><b>UUIDv6</b> - now V6 is very similar to V1 flipping the timestamps, meaning the most significant portions of the timestamp are stored first. now in turn this makes it a little more <b>sortable</b>, since the most significant portion of the timestamp is upfront</li>
  <br>
  <li><b>UUIDv7</b> - now this is the only version I can think of using in come cases instead of V4, this basically finally uses the <b>UNIX timestamp</b> instead of the Gregorian calendar and the rest of the string is just random alphanumerics, which makes it less trackable back to their source and this is what we will discuss moving forward</li>
  <br>
  <li><b>UUIDv8</b> - this permits vendor-specific implementations while adhering to RFC standards and the illustration says its more of a vibe then a standard now</li>
</ul>

<img src="./assets/uuid.png", width='100%'></img>
<h3>The Diffusion Process: A Sparse Overview</h3>
<p style="color: red"><b>! There are very good guides on how diffusion works online this is just a sparse introduction to the diffusion process to build up the notion !</b></p>
<p>The diffusion process is an iterative mechanism that converts random noise into an image. This process can be broadly divided into two stages: forward diffusion and reverse diffusion. Let's delve into these stages to understand their technical intricacies.</p>
<h4>Forward Diffusion: Adding Noise</h4>
<p>The forward diffusion process gradually corrupts an image by adding Gaussian noise over several steps. Mathematically, it is described by the following equation:</p>
<p>\(q(x_t \mid x_{t-1}) = \mathcal{N}(x_t; (1 - \beta_t) x_{t-1}, \beta_t I)\)</p>
<p>
<ul>
    <li>\(x_t\) represents the noisy latent variable at timestep \(t\).</li>
    <li>\(\beta_t\) is the variance schedule, controlling the amount of noise added at each step.</li>
    <li>\(\mathcal{N}\) denotes a Gaussian distribution.</li>
</ul>
</p>
<p>Over time, the image is transformed into pure noise, which serves as the starting point for the reverse diffusion process.</p>
<h4>Reverse Diffusion: Removing Noise</h4>
<p>The reverse diffusion process, guided by a pre-trained model, aims to denoise the noisy latent variables step-by-step, eventually reconstructing a high-quality image. This is expressed as:</p>
<p>
    \(p_\theta(x_{t-1} \mid x_t, \mathbf{s}) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t, \mathbf{s}), \Sigma_\theta(x_t, t, \mathbf{s}))\) where:
</p>
<ul>
    <li>\(\mu_\theta(x_t, t, \mathbf{s})\) is the predicted mean, influenced by the current state \(x_t\), timestep \(t\), and the seed \(\mathbf{s}\).</li>
    <li>\(\Sigma_\theta(x_t, t, \mathbf{s})\) is the predicted variance.</li>
    <li>\(\mathbf{s}\) is the seed, which ensures the process is stochastic but repeatable.</li>
</ul>
</p>
<p style="color: orange"><b>[Appendix A]</b></p>

<h3>Seeds: The Architects of Randomness</h3>
<p>Moving on to the core focus of the this blog: Seeds play a crucial role in this process. Each seed initializes the random number generator that produces the initial noise and the noise added at each reverse diffusion step. Consequently, the choice of seed can lead to vastly different generated images even for the same textual description</p>
<h3>Exploring the Impact of Seeds</h3>
<p>To illustrate the profound impact of seeds, let's consider two examples:
<ul>
  <li>Best Seed (FID <b style="color: orange">[Appendix B]</b>: 21.60): Seed 469</li>
  <li>Worst Seed (FID: 31.97): Seed 696</li>
</ul>
These seeds were identified through extensive experimentation and analysis from the authors. The FID score, where lower values indicate higher quality, highlights how the choice of seed can significantly affect the output quality.
</p>
<img src='./assets/graph_seed.png', width='100%'>
<h3>Seed and Intermediate Noise</h3>
<p>
An interesting facet of the seed's influence is its effect on intermediate noise levels during the reverse diffusion process. Our experiments and the experiments from the paper revealed that while the initial noise predominantly determines the final image, the noise added at each step, controlled by the seed, does not really affect the quality or has any substantial change in the final output.
</p>
<img src='./assets/seed_exp1.jpg', width='100%'>
<p style="font-size:11px; margin-top:-20px">we first set the seed to `i` and begin the reverse diffusion process. Then, at an intermediate timestep, we change the seed to `j` and complete the image generation process. We explore using seeds 0 and 1 for both `i` and `j`, as well as swapping the seed at early, mid, and late timesteps respectively of the reverse diffusion process. Despite these variations, we found that the initial noisy latent significantly controls the generated content, while the random noise introduced at intermediate reparameterization steps has no visible impact on the generated images</p>
<h3>Visual Fingerprints: The Seeds' Distinguishing Marks</h3>
<p>Each seed imprints a unique "visual fingerprint" on the generated images. The authors from the paper trained a 1,024-way classifier to predict the seed from an image with over 99.9% accuracy, demonstrating the distinct influence of seeds. This classifier revealed that even subtle variations in noise, dictated by the seed, result in distinguishable visual features. These findings suggest that seeds may encode unique visual features, prompting us to explore their impact across several interpretable dimensions</p>
<p>The authors reduced the dimensions in order to better classify the seeds according to the features which resulted in some seeds giving certain features in the output i.e. having a frame around the image even though not prompted to, having a white sky instead of a blue sky, giving a grayscaled output etc.</p>
<img src='./assets/seed_gray.png', width='100%'>
<p style="font-size:11px; margin-top:-20px"> For more details and a detailed overview of all the methods and results mentioned go read the paper <a> https://arxiv.org/abs/2405.14828 </a></p>
<h3>Applications: High-Fidelity Inference and Diversified Sampling</h3>
<p>By identifying and leveraging "golden seeds," we can:
<ul>
  <li>Enhance high-fidelity inference by limiting sampling to top-K seeds, improving FID scores.</li>
  <li>Enable diversified sampling based on style or layout, providing users with a variety of visually distinct images.</li>
  <li>Improve inpainting quality by avoiding seeds that introduce unwanted text artifacts.</li>
</ul>
</p>

<h3>Conclusion: The Magic of Good Seeds</h3>
<p>Our journey through the randomness of seeds in T2I diffusion models reveals that not all seeds are created equal. By understanding and leveraging the power of good seeds, we can push the boundaries of what’s possible in image generation. Stay tuned for more deep dives and keep those seeds planted firmly in the fertile ground of your curiosity.

And remember, in the world of T2I diffusion, a good seed makes a good crop.
</p>
<br>
<hr>
<h3><b style="color:orange">Appendix A</b> : Diffusion Process Equations</h3>

<p>The forward diffusion process: \(q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1-\beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I})\)</p>

<p>Reverse process given the seed: \(p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t, \mathbf{s}) = \mathcal{N}(\mathbf{x}_{t-1}; \mu_\theta(\mathbf{x}_t, t, \mathbf{s}), \Sigma_\theta(\mathbf{x}_t, t, \mathbf{s}))\)</p>

<p>where \(\mu_\theta\) and \(\Sigma_\theta\) are defined as:</p>

<p>\(\mu_\theta(\mathbf{x}_t, t, \mathbf{s}) = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t, t, \mathbf{s}) \right)\)</p>
<p>\(\Sigma_\theta(\mathbf{x}_t, t, \mathbf{s}) = \sigma_t^2 \mathbf{I}\)</p>

<p>with \(\alpha_t = 1 - \beta_t\) and \(\bar{\alpha}_t = \prod_{i=1}^t \alpha_i\). The term \(\epsilon_\theta(\mathbf{x}_t, t, \mathbf{s})\) is the noise predictor, a crucial part of the denoising process influenced by the seed.</p>

<h3><b style="color: orange">Appendix B</b> : Fréchet Inception Distance (FID) </h3>
<p>The FID score calculation involves the mean \(\mu\) and covariance \(\Sigma\) of the real and generated image distributions:</p>

<p>\(\text{FID} = || \mu_r - \mu_g ||^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})\)</p>

<p>Lower FID scores indicate better quality images, as the distribution of generated images is closer to that of real images.</p>

<p>By leveraging these mathematical frameworks, we can fine-tune the generation process to yield visually stunning and high-quality images with the right seeds. Happy seeding!</p>

<h5> Related Work </h5>
<p style="font-size:12px">arXiv:2404.11120, arXiv:2404.04650, arXiv:2312.08872 and others have aimed to optimize the initial noise to produce images that better align with the text prompt, reduce visual artifacts, or achieve a desired layout
    </body>
</html>
